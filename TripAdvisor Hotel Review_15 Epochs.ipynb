{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Transformers for Sentiment Classification:**","metadata":{"id":"s7x5pLnQz0mZ"}},{"cell_type":"markdown","source":"Welcome folks!, in the current project I will show you in detail how to implement four types of well-known transformer models making use of the transformers HuggingFace library and Keras API.\n\nThe main task corresponds to a multi-class text classification on Movie Reviews Competition and the dataset contains 156.060 instances for training, whereas the testing set contains 66.292 from which we have to classify among 5 classes. The sentiment labels are:\n\n0 → Negative\n1 → Somewhat negative\n2 → Neutral\n3 → Somewhat positive\n4 → Positive\nAt the end of the project we will summarize and compare their performance according to our requirements and metrics.","metadata":{"id":"KRGB_C7Bz8-H"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-09-12T11:06:56.405231Z","iopub.execute_input":"2022-09-12T11:06:56.405815Z","iopub.status.idle":"2022-09-12T11:06:56.439945Z","shell.execute_reply.started":"2022-09-12T11:06:56.405688Z","shell.execute_reply":"2022-09-12T11:06:56.439067Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os \n!pip install -U -q segmentation-models --user\nos.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\nimport segmentation_models as sm","metadata":{"execution":{"iopub.status.busy":"2022-09-12T11:06:56.443117Z","iopub.execute_input":"2022-09-12T11:06:56.444011Z","iopub.status.idle":"2022-09-12T11:07:13.614094Z","shell.execute_reply.started":"2022-09-12T11:06:56.443976Z","shell.execute_reply":"2022-09-12T11:07:13.612992Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install Keras","metadata":{"execution":{"iopub.status.busy":"2022-09-12T11:07:13.615490Z","iopub.execute_input":"2022-09-12T11:07:13.616853Z","iopub.status.idle":"2022-09-12T11:07:23.002064Z","shell.execute_reply.started":"2022-09-12T11:07:13.616805Z","shell.execute_reply":"2022-09-12T11:07:23.000791Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport seaborn as sns\nsns.set(style='whitegrid')\n\nfrom wordcloud import WordCloud\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.metrics import classification_report,confusion_matrix\n\nfrom collections import defaultdict\nfrom collections import Counter\n\nimport re\nimport gensim\nimport string\n\nfrom tqdm import tqdm\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, LSTM,Dense, SpatialDropout1D, Dropout\nfrom keras.initializers import Constant\n\nimport tensorflow as tf\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"id":"krJ5OvxMZ8C3","execution":{"iopub.status.busy":"2022-09-12T11:07:23.008240Z","iopub.execute_input":"2022-09-12T11:07:23.010832Z","iopub.status.idle":"2022-09-12T11:07:23.578858Z","shell.execute_reply.started":"2022-09-12T11:07:23.010791Z","shell.execute_reply":"2022-09-12T11:07:23.577962Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\n#df=pd.read_csv(\"../input/amazon-reviews-on-sentiment-analysis/Amazon Reviews on Sentiment Analysis/train.csv\")\n#encoding='latin1', lineterminator='\\n'\ndframe = pd.read_csv(\"../input/tripadvisor-hotel-reviews-20k-dataset/tripadvisor_hotel_reviews.csv\")\n#df, validate, df_test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])","metadata":{"id":"kushm0ptZ-nF","execution":{"iopub.status.busy":"2022-09-12T11:07:23.584257Z","iopub.execute_input":"2022-09-12T11:07:23.586470Z","iopub.status.idle":"2022-09-12T11:07:23.886380Z","shell.execute_reply.started":"2022-09-12T11:07:23.586432Z","shell.execute_reply":"2022-09-12T11:07:23.885360Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Just to confirm the number of instances and features in each file:","metadata":{"id":"9JiDvbxjaIhl"}},{"cell_type":"code","source":"df = dframe.sample(frac=0.8, random_state=25)\ndf_test = dframe.drop(df.index)\n\nprint(f\"No. of training examples: {df.shape[0]}\")\nprint(f\"No. of testing examples: {df_test.shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-12T11:07:23.887848Z","iopub.execute_input":"2022-09-12T11:07:23.888228Z","iopub.status.idle":"2022-09-12T11:07:23.906266Z","shell.execute_reply.started":"2022-09-12T11:07:23.888190Z","shell.execute_reply":"2022-09-12T11:07:23.905301Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#df_test=pd.read_csv(\"../input/amazon-reviews-on-sentiment-analysis/Amazon Reviews on Sentiment Analysis/test.csv\")\n#encoding='latin1', lineterminator='\\n'","metadata":{"execution":{"iopub.status.busy":"2022-09-12T11:07:23.907883Z","iopub.execute_input":"2022-09-12T11:07:23.908372Z","iopub.status.idle":"2022-09-12T11:07:23.913427Z","shell.execute_reply.started":"2022-09-12T11:07:23.908328Z","shell.execute_reply":"2022-09-12T11:07:23.912395Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df.shape, df_test.shape","metadata":{"id":"VE5kz4rsaJ2E","execution":{"iopub.status.busy":"2022-09-12T11:07:23.915004Z","iopub.execute_input":"2022-09-12T11:07:23.916248Z","iopub.status.idle":"2022-09-12T11:07:23.927165Z","shell.execute_reply.started":"2022-09-12T11:07:23.916211Z","shell.execute_reply":"2022-09-12T11:07:23.925971Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"id":"HIfkSkz_aMPa","execution":{"iopub.status.busy":"2022-09-12T11:07:23.928710Z","iopub.execute_input":"2022-09-12T11:07:23.929198Z","iopub.status.idle":"2022-09-12T11:07:23.948849Z","shell.execute_reply.started":"2022-09-12T11:07:23.929162Z","shell.execute_reply":"2022-09-12T11:07:23.947799Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Above we can see that Review and Rating columns are all we need from the file in order to train the models later, therefore we will use these as feature (X) and label (Y) when fitting the transformer.","metadata":{"id":"mrBUkUGoaTSs"}},{"cell_type":"code","source":"df_test","metadata":{"id":"s7oYfe8eaYrZ","execution":{"iopub.status.busy":"2022-09-12T11:07:23.953132Z","iopub.execute_input":"2022-09-12T11:07:23.953394Z","iopub.status.idle":"2022-09-12T11:07:23.966212Z","shell.execute_reply.started":"2022-09-12T11:07:23.953370Z","shell.execute_reply":"2022-09-12T11:07:23.964954Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"In case there is a null or empty value in any column we should have to get rid of it, in order to find it out we will use info() as follows:","metadata":{"id":"QReUqBkgafzB"}},{"cell_type":"code","source":"df.info()","metadata":{"id":"00ROHkd1agl0","execution":{"iopub.status.busy":"2022-09-12T11:07:23.968166Z","iopub.execute_input":"2022-09-12T11:07:23.968555Z","iopub.status.idle":"2022-09-12T11:07:23.992445Z","shell.execute_reply.started":"2022-09-12T11:07:23.968522Z","shell.execute_reply":"2022-09-12T11:07:23.991393Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"id":"t4rCZTO0ai6l","execution":{"iopub.status.busy":"2022-09-12T11:07:23.994071Z","iopub.execute_input":"2022-09-12T11:07:23.994560Z","iopub.status.idle":"2022-09-12T11:07:24.007036Z","shell.execute_reply.started":"2022-09-12T11:07:23.994469Z","shell.execute_reply":"2022-09-12T11:07:24.005889Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"The dataset looks good and we need to know how are distributed the 5 classes in the label so as to know it's balanced or not.","metadata":{"id":"qTNsHB3taqKd"}},{"cell_type":"code","source":"df.Rating.value_counts()","metadata":{"id":"a8lX6Qfhaq2C","execution":{"iopub.status.busy":"2022-09-12T11:07:24.009859Z","iopub.execute_input":"2022-09-12T11:07:24.010838Z","iopub.status.idle":"2022-09-12T11:07:24.020284Z","shell.execute_reply.started":"2022-09-12T11:07:24.010801Z","shell.execute_reply":"2022-09-12T11:07:24.018946Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df2=df.copy(deep=True)\npie1=pd.DataFrame(df2['Rating'].replace(1,'Negative').replace(2,'Somewhat negative').replace(3,'Neutral').replace(4,'Somewhat positive').replace(5,'Positive').value_counts())\npie1.reset_index(inplace=True)\npie1.plot(kind='pie', title='Pie chart of Rating Class',y = 'Rating', \n          autopct='%1.1f%%', shadow=False, labels=pie1['index'], legend = False, fontsize=14, figsize=(12,12))","metadata":{"id":"4Yvovrb8atKX","execution":{"iopub.status.busy":"2022-09-12T11:07:24.021569Z","iopub.execute_input":"2022-09-12T11:07:24.021832Z","iopub.status.idle":"2022-09-12T11:07:24.294216Z","shell.execute_reply.started":"2022-09-12T11:07:24.021809Z","shell.execute_reply":"2022-09-12T11:07:24.293325Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Time now to find out the number of words in reviews, in order to understand a bit better we will plot histograms for each class","metadata":{"id":"XJfTznoca4Cn"}},{"cell_type":"code","source":"f, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5,figsize=(25,8))\n\nax1.hist(df[df['Rating'] == 1]['Review'].str.split().map(lambda x: len(x)), bins=50, color='b')\nax1.set_title('Negative Reviews')\n\nax2.hist(df[df['Rating'] == 2]['Review'].str.split().map(lambda x: len(x)), bins=50, color='r')\nax2.set_title('Somewhat Negative Reviews')\n\nax3.hist(df[df['Rating'] == 3]['Review'].str.split().map(lambda x: len(x)), bins=50, color='g')\nax3.set_title('Neutral Reviews')\n\nax4.hist(df[df['Rating'] == 4]['Review'].str.split().map(lambda x: len(x)), bins=50, color='y')\nax4.set_title('Somewhat Positive Reviews')\n\nax5.hist(df[df['Rating'] == 5]['Review'].str.split().map(lambda x: len(x)), bins=50, color='k')\nax5.set_title('Positive Reviews')\n\nf.suptitle('Histogram number of words in reviews')","metadata":{"id":"ZnyuH5dda423","execution":{"iopub.status.busy":"2022-09-12T11:07:24.295782Z","iopub.execute_input":"2022-09-12T11:07:24.296266Z","iopub.status.idle":"2022-09-12T11:07:25.750000Z","shell.execute_reply.started":"2022-09-12T11:07:24.296223Z","shell.execute_reply":"2022-09-12T11:07:25.748844Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"In the 5 histograms we can see the distribution behaves like a negative exponential function decreasing significatively as the x-axis increases. It seems like the longest sentence in Review column corresponds to a class 'Negative Reviews' and is around 52 words, now let's obtain the longest one by using the max() function:","metadata":{"id":"KqjcKXkQa_TG"}},{"cell_type":"code","source":"df['Review'].str.split().map(lambda x: len(x)).max()","metadata":{"id":"OuibTLIYbFnL","execution":{"iopub.status.busy":"2022-09-12T11:07:25.751570Z","iopub.execute_input":"2022-09-12T11:07:25.751954Z","iopub.status.idle":"2022-09-12T11:07:26.000858Z","shell.execute_reply.started":"2022-09-12T11:07:25.751897Z","shell.execute_reply":"2022-09-12T11:07:25.999180Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"dfff=pd.DataFrame(df['Review'].str.split().map(lambda x: len(x))>=20)\nprint('Number of sentences which contain more than 20 words: ', dfff.loc[dfff['Review']==True].shape[0])\nprint(' ')\ndfff=pd.DataFrame(df['Review'].str.split().map(lambda x: len(x))>=30)\nprint('Number of sentences which contain more than 30 words: ', dfff.loc[dfff['Review']==True].shape[0])\nprint(' ')\ndfff=pd.DataFrame(df['Review'].str.split().map(lambda x: len(x))>=40)\nprint('Number of sentences which contain more than 40 words: ', dfff.loc[dfff['Review']==True].shape[0])\nprint(' ')\ndfff=pd.DataFrame(df['Review'].str.split().map(lambda x: len(x))>=50)\nprint('Number of sentences which contain more than 50 words: ', dfff.loc[dfff['Review']==True].shape[0])\nprint(' ')\ndfff=pd.DataFrame(df['Review'].str.split().map(lambda x: len(x))==52)\nprint('Number of sentences which contain 52 words: ', dfff.loc[dfff['Review']==True].shape[0])\nprint(' ')","metadata":{"id":"xJR3fJu9bH6Q","execution":{"iopub.status.busy":"2022-09-12T11:07:26.006337Z","iopub.execute_input":"2022-09-12T11:07:26.009068Z","iopub.status.idle":"2022-09-12T11:07:27.579174Z","shell.execute_reply.started":"2022-09-12T11:07:26.009027Z","shell.execute_reply":"2022-09-12T11:07:27.578083Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Modeling\nIn this step we will build, train and compare the following algorithms:\n\nBERT (Bidirectional Encoder Representation from Transformers)\n\nXLNet (Generalized Auto-Regressive model)\n\nRoBERTa (Robustly Optimized BERT Pre-training Approach)\n\nDistilBERT (Distilled BERT)\n\nEach one of the mentioned have its pros and cons, the most preferred and widely used model is the BERT for being the middle term in performance, whereas RoBERTa and .. are known for their better error metrics and DistilBERT for its faster training. We will consider all of these chracteristics and choose the best one for our dataset.\n\nFirstly, we have to install the transformers library offered by HuggingFace so as enable all useful functions when building the four models.","metadata":{"id":"Vo4zUyWBbV_Y"}},{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"3hMEfpzvbfY3","execution":{"iopub.status.busy":"2022-09-12T11:07:27.580785Z","iopub.execute_input":"2022-09-12T11:07:27.581828Z","iopub.status.idle":"2022-09-12T11:07:36.510286Z","shell.execute_reply.started":"2022-09-12T11:07:27.581788Z","shell.execute_reply":"2022-09-12T11:07:36.509099Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Then what we need from tensorflow.keras:","metadata":{"id":"Fd7nKMZbbziI"}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dropout, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.initializers import TruncatedNormal\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.metrics import CategoricalAccuracy\nfrom tensorflow.keras.utils import to_categorical\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"id":"fTi84tvib0YN","execution":{"iopub.status.busy":"2022-09-12T11:07:36.513151Z","iopub.execute_input":"2022-09-12T11:07:36.514062Z","iopub.status.idle":"2022-09-12T11:07:36.525883Z","shell.execute_reply.started":"2022-09-12T11:07:36.514028Z","shell.execute_reply":"2022-09-12T11:07:36.524846Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Now we have to gather from the dataset only the two columns useful for training (Review and Rating):","metadata":{"id":"3OFxlNp-b4Sv"}},{"cell_type":"code","source":"data = df[['Review', 'Rating']]\n\n# Set your model output as categorical and save in new label col\ndata['Rating_label'] = pd.Categorical(data['Rating'])\n\n# Transform your output to numeric\ndata['Rating'] = data['Rating_label'].cat.codes","metadata":{"id":"pxp_0agMcBXd","execution":{"iopub.status.busy":"2022-09-12T11:07:36.528086Z","iopub.execute_input":"2022-09-12T11:07:36.528438Z","iopub.status.idle":"2022-09-12T11:07:36.546251Z","shell.execute_reply.started":"2022-09-12T11:07:36.528402Z","shell.execute_reply":"2022-09-12T11:07:36.545403Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"data_train, data_val = train_test_split(data, test_size = 0.1)","metadata":{"id":"18FNY-EbcEmD","execution":{"iopub.status.busy":"2022-09-12T11:07:36.547792Z","iopub.execute_input":"2022-09-12T11:07:36.548465Z","iopub.status.idle":"2022-09-12T11:07:36.556667Z","shell.execute_reply.started":"2022-09-12T11:07:36.548419Z","shell.execute_reply":"2022-09-12T11:07:36.555632Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# **BERT:**\n\n","metadata":{"id":"3QCYluH-cWWy"}},{"cell_type":"markdown","source":"As first step we have to import the Model, Config and Tokenizer corresponding to Bert in order to build properly the model.","metadata":{"id":"S1S8M3VjcjwC"}},{"cell_type":"code","source":"from transformers import TFBertModel,  BertConfig, BertTokenizerFast","metadata":{"id":"8fY-lIO_c5eJ","execution":{"iopub.status.busy":"2022-09-12T11:07:36.558340Z","iopub.execute_input":"2022-09-12T11:07:36.559035Z","iopub.status.idle":"2022-09-12T11:07:43.781243Z","shell.execute_reply.started":"2022-09-12T11:07:36.558998Z","shell.execute_reply":"2022-09-12T11:07:43.780184Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Name of the BERT model to use\nmodel_name = 'bert-base-uncased'\n\n# Max length of tokens\nmax_length = 100\n\n# Load transformers config and set output_hidden_states to False\nconfig = BertConfig.from_pretrained(model_name)\nconfig.output_hidden_states = False\n\n# Load BERT tokenizer\ntokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n\n# Load the Transformers BERT model\ntransformer_bert_model = TFBertModel.from_pretrained(model_name, config = config)","metadata":{"id":"FyTDXRXYd1mF","execution":{"iopub.status.busy":"2022-09-12T11:07:43.782802Z","iopub.execute_input":"2022-09-12T11:07:43.783450Z","iopub.status.idle":"2022-09-12T11:08:13.331468Z","shell.execute_reply.started":"2022-09-12T11:07:43.783412Z","shell.execute_reply":"2022-09-12T11:08:13.330477Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Now that our model has been loaded we can start the processes of building and tuning according to our dataset and task using the functional API of keras.","metadata":{"id":"zMuMyWQIeSY9"}},{"cell_type":"code","source":"### ------- Build the model ------- ###\n\n# Load the MainLayer\nbert = transformer_bert_model.layers[0]\n\n# Build your model input\ninput_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\ninputs = {'input_ids': input_ids}\n\n# Load the Transformers BERT model as a layer in a Keras model\nbert_model = bert(inputs)[1]\ndropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\npooled_output = dropout(bert_model, training=False)\n\n# Then build your model output\nRatings = Dense(units=len(data_train.Rating_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='Rating')(pooled_output)\noutputs = {'Rating': Ratings}\n\n# And combine it all in a model object\nmodel = Model(inputs=inputs, outputs=outputs, name='BERT_MultiClass')\n\n# Take a look at the model\nmodel.summary()","metadata":{"id":"djdSChZYeTVK","execution":{"iopub.status.busy":"2022-09-12T11:08:13.333825Z","iopub.execute_input":"2022-09-12T11:08:13.334753Z","iopub.status.idle":"2022-09-12T11:08:19.656990Z","shell.execute_reply.started":"2022-09-12T11:08:13.334713Z","shell.execute_reply":"2022-09-12T11:08:19.655969Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"The next cell considers the tokenization of training and testing sentences, setting of label as categorical and finally model training.","metadata":{"id":"Sz21QW3eecqH"}},{"cell_type":"code","source":"### ------- Train the model ------- ###\n\n# Set an optimizer\noptimizer = Adam(learning_rate=5e-05,epsilon=1e-08,decay=0.01,clipnorm=1.0)\n\n# Set loss and metrics\nloss = {'Rating': CategoricalCrossentropy(from_logits = True)}\n\n# Compile the model\nmodel.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy'])\n\n# Ready output data for the model\ny_train = to_categorical(data_train['Rating'])\n\n# Tokenize the input (takes some time)\nx_train = tokenizer(\n          text=data_train['Review'].to_list(),\n          add_special_tokens=True,\n          max_length=max_length,\n          truncation=True,\n          padding=True, \n          return_tensors='tf',\n          return_token_type_ids = False,\n          return_attention_mask = True,\n          verbose = True)\n# Fit the model\nhistory = model.fit(\n    x={'input_ids': x_train['input_ids']},\n    y={'Rating': y_train},\n    \n    batch_size=64,\n    epochs=10,\n    verbose=1)","metadata":{"id":"u1X-loeVegrp","execution":{"iopub.status.busy":"2022-09-12T11:08:19.658546Z","iopub.execute_input":"2022-09-12T11:08:19.660204Z","iopub.status.idle":"2022-09-12T11:36:07.218236Z","shell.execute_reply.started":"2022-09-12T11:08:19.660164Z","shell.execute_reply":"2022-09-12T11:36:07.217191Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"The model took 31 minutes and 16 seconds to train for 2 epochs.","metadata":{"id":"8QKJ2hs0jMUz"}},{"cell_type":"markdown","source":"# **Evaluate on Train+Test set(BERT):**","metadata":{"id":"r-xdmq0ee1eo"}},{"cell_type":"markdown","source":"We will compute the error metrics on the validation set in order to have an idea of the model performance.","metadata":{"id":"NvI5x3vtfFwX"}},{"cell_type":"code","source":"model_eval = model.evaluate(\n    x={'input_ids': x_train['input_ids']},\n    y={'Rating': y_train}\n)","metadata":{"id":"Lo097P8KfIEE","outputId":"49492c49-081a-40b0-a8ae-4c3f60944c05","execution":{"iopub.status.busy":"2022-09-12T11:36:07.219928Z","iopub.execute_input":"2022-09-12T11:36:07.220342Z","iopub.status.idle":"2022-09-12T11:37:12.856387Z","shell.execute_reply.started":"2022-09-12T11:36:07.220304Z","shell.execute_reply":"2022-09-12T11:37:12.855448Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"y_train_predicted = model.predict(\n    x={'input_ids': x_train['input_ids']},\n)","metadata":{"id":"igLsjwLNfLYU","execution":{"iopub.status.busy":"2022-09-12T11:37:12.858145Z","iopub.execute_input":"2022-09-12T11:37:12.858866Z","iopub.status.idle":"2022-09-12T11:38:16.347797Z","shell.execute_reply.started":"2022-09-12T11:37:12.858827Z","shell.execute_reply":"2022-09-12T11:38:16.346769Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"y_train_predicted corresponds to a numpy array representing the instances and the prediction as one-hot encoded, the actual label is formatted in the same manner, let's them see in detail:","metadata":{"id":"YJ-ZJBpsfrim"}},{"cell_type":"code","source":"y_train_predicted['Rating']","metadata":{"id":"1h_8U9FQfu9N","execution":{"iopub.status.busy":"2022-09-12T11:38:16.355833Z","iopub.execute_input":"2022-09-12T11:38:16.356155Z","iopub.status.idle":"2022-09-12T11:38:16.364258Z","shell.execute_reply.started":"2022-09-12T11:38:16.356128Z","shell.execute_reply":"2022-09-12T11:38:16.363291Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"y_train_predicted['Rating']","metadata":{"id":"jM1Q3VEJfyJJ","execution":{"iopub.status.busy":"2022-09-12T11:38:16.365669Z","iopub.execute_input":"2022-09-12T11:38:16.366302Z","iopub.status.idle":"2022-09-12T11:38:16.380918Z","shell.execute_reply.started":"2022-09-12T11:38:16.366261Z","shell.execute_reply":"2022-09-12T11:38:16.379951Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"In order to compute the classification report and confusion matrix we will convert the matrices to one column representing the argmax for each row:","metadata":{"id":"09ljA2ypf5Yr"}},{"cell_type":"code","source":"y_train_pred_max=[np.argmax(i) for i in y_train_predicted['Rating']]","metadata":{"id":"5oLJpsWof6k9","execution":{"iopub.status.busy":"2022-09-12T11:38:16.382182Z","iopub.execute_input":"2022-09-12T11:38:16.383298Z","iopub.status.idle":"2022-09-12T11:38:16.415757Z","shell.execute_reply.started":"2022-09-12T11:38:16.383265Z","shell.execute_reply":"2022-09-12T11:38:16.414919Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"y_train_actual_max=[np.argmax(i) for i in y_train]","metadata":{"id":"jQIWtNy0gBVU","execution":{"iopub.status.busy":"2022-09-12T11:38:16.418402Z","iopub.execute_input":"2022-09-12T11:38:16.419066Z","iopub.status.idle":"2022-09-12T11:38:16.450097Z","shell.execute_reply.started":"2022-09-12T11:38:16.419032Z","shell.execute_reply":"2022-09-12T11:38:16.449235Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nreport = classification_report(y_train_pred_max, y_train_actual_max)\n\nprint(report)","metadata":{"id":"iaX1Za9mgFgT","execution":{"iopub.status.busy":"2022-09-12T11:38:16.451536Z","iopub.execute_input":"2022-09-12T11:38:16.452179Z","iopub.status.idle":"2022-09-12T11:38:16.488989Z","shell.execute_reply.started":"2022-09-12T11:38:16.452146Z","shell.execute_reply":"2022-09-12T11:38:16.488054Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"The fact that our dataset is unbalanced in classes makes our prediction absolutely sidetracked towards the most frequent class, in this case (2: 'Neutral'), because of this the performance of the model is poor when predicting classes 0 or 4, making our model almost unuseful for this task. Below we can see for these 2 classes the number of misclassifications is huge.","metadata":{"id":"jrTK371lgPWX"}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train_pred_max, y_train_actual_max), display_labels=np.unique(y_train_actual_max))\ndisp.plot(cmap='Blues') \nplt.grid(False)","metadata":{"id":"AY7DBDiagQXI","execution":{"iopub.status.busy":"2022-09-12T11:38:16.490503Z","iopub.execute_input":"2022-09-12T11:38:16.491157Z","iopub.status.idle":"2022-09-12T11:38:16.805634Z","shell.execute_reply.started":"2022-09-12T11:38:16.491122Z","shell.execute_reply":"2022-09-12T11:38:16.804775Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# **Inference(BERT):**","metadata":{"id":"IGE6T_d6gUaC"}},{"cell_type":"markdown","source":"In this step we will predict the classes corresponding to the test set (out-of-bag) instances, because of the huge dataset we can expect to have almost same performance.","metadata":{"id":"VNIQ8Twpgme-"}},{"cell_type":"code","source":"x_test = tokenizer(\n          text=df_test['Review'].to_list(),\n          add_special_tokens=True,\n          max_length=max_length,\n          truncation=True,\n          padding=True, \n          return_tensors='tf',\n          return_token_type_ids = False,\n          return_attention_mask = False,\n          verbose = True)","metadata":{"id":"fPD_I4Xmgp4o","execution":{"iopub.status.busy":"2022-09-12T11:38:16.808034Z","iopub.execute_input":"2022-09-12T11:38:16.808535Z","iopub.status.idle":"2022-09-12T11:38:19.212279Z","shell.execute_reply.started":"2022-09-12T11:38:16.808509Z","shell.execute_reply":"2022-09-12T11:38:19.211210Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"label_predicted = model.predict(\n    x={'input_ids': x_test['input_ids']},\n)","metadata":{"id":"X541UmDBgryf","execution":{"iopub.status.busy":"2022-09-12T11:38:19.213980Z","iopub.execute_input":"2022-09-12T11:38:19.214643Z","iopub.status.idle":"2022-09-12T11:38:36.073842Z","shell.execute_reply.started":"2022-09-12T11:38:19.214605Z","shell.execute_reply":"2022-09-12T11:38:36.072820Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"label_predicted['Rating']","metadata":{"id":"OKgN4m0dgtVR","execution":{"iopub.status.busy":"2022-09-12T11:38:36.075479Z","iopub.execute_input":"2022-09-12T11:38:36.075852Z","iopub.status.idle":"2022-09-12T11:38:36.085831Z","shell.execute_reply.started":"2022-09-12T11:38:36.075817Z","shell.execute_reply":"2022-09-12T11:38:36.084557Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"label_pred_max=[np.argmax(i) for i in label_predicted['Rating']]","metadata":{"id":"tMNOz0JCgy8X","execution":{"iopub.status.busy":"2022-09-12T11:38:36.087730Z","iopub.execute_input":"2022-09-12T11:38:36.088171Z","iopub.status.idle":"2022-09-12T11:38:36.102798Z","shell.execute_reply.started":"2022-09-12T11:38:36.088135Z","shell.execute_reply":"2022-09-12T11:38:36.101948Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"label_pred_max[:10]","metadata":{"id":"v5YbQO_cg1EA","execution":{"iopub.status.busy":"2022-09-12T11:38:36.104198Z","iopub.execute_input":"2022-09-12T11:38:36.104766Z","iopub.status.idle":"2022-09-12T11:38:36.111941Z","shell.execute_reply.started":"2022-09-12T11:38:36.104732Z","shell.execute_reply":"2022-09-12T11:38:36.110941Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"We will build the next 3 models the same way as the previous one, notice there are some lines which includes extra functions proper for the model:","metadata":{"id":"c2GIUSsrg6TU"}},{"cell_type":"code","source":"#Cheers!!!","metadata":{"id":"C2exxHYKg7MW","execution":{"iopub.status.busy":"2022-09-12T11:38:36.113492Z","iopub.execute_input":"2022-09-12T11:38:36.114253Z","iopub.status.idle":"2022-09-12T11:38:36.118922Z","shell.execute_reply.started":"2022-09-12T11:38:36.114218Z","shell.execute_reply":"2022-09-12T11:38:36.117946Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"# **XLNet:**","metadata":{"id":"0iqRcZoXhWIY"}},{"cell_type":"markdown","source":"The tokenizer corresponding to XLNet requires an extra library called sentencepiece which we have to install and import as follows:","metadata":{"id":"6oI59xQ1hles"}},{"cell_type":"code","source":"!pip install sentencepiece ","metadata":{"id":"MBAb1rP3hmWH","execution":{"iopub.status.busy":"2022-09-12T11:38:36.120403Z","iopub.execute_input":"2022-09-12T11:38:36.121012Z","iopub.status.idle":"2022-09-12T11:38:45.421803Z","shell.execute_reply.started":"2022-09-12T11:38:36.120978Z","shell.execute_reply":"2022-09-12T11:38:45.420626Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"from transformers import XLNetTokenizer, TFXLNetModel, XLNetConfig\nimport sentencepiece","metadata":{"id":"fhc1W-Ynh1dl","execution":{"iopub.status.busy":"2022-09-12T11:38:45.423919Z","iopub.execute_input":"2022-09-12T11:38:45.424370Z","iopub.status.idle":"2022-09-12T11:38:45.444726Z","shell.execute_reply.started":"2022-09-12T11:38:45.424325Z","shell.execute_reply":"2022-09-12T11:38:45.443839Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"### --------- Setup XLNet ---------- ###\n\nmodel_name = 'xlnet-base-cased'\n\n# Max length of tokens\nmax_length = 100\n\n# Load transformers config and set output_hidden_states to False\nconfig = XLNetConfig.from_pretrained(model_name)\nconfig.output_hidden_states = False\n\n# Load XLNet tokenizer\ntokenizer = XLNetTokenizer.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n\n# Load the XLNet model\ntransformer_xlnet_model = TFXLNetModel.from_pretrained(model_name, config = config)","metadata":{"id":"ZHQCXAnWh58X","execution":{"iopub.status.busy":"2022-09-12T11:38:45.446146Z","iopub.execute_input":"2022-09-12T11:38:45.446862Z","iopub.status.idle":"2022-09-12T11:39:17.975531Z","shell.execute_reply.started":"2022-09-12T11:38:45.446828Z","shell.execute_reply":"2022-09-12T11:39:17.974535Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Input\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-09-12T11:39:17.977098Z","iopub.execute_input":"2022-09-12T11:39:17.977429Z","iopub.status.idle":"2022-09-12T11:39:17.981922Z","shell.execute_reply.started":"2022-09-12T11:39:17.977395Z","shell.execute_reply":"2022-09-12T11:39:17.980951Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"### ------- Build the model ------- ###\n\n# Load the MainLayer\nxlnet = transformer_xlnet_model.layers[0]\n\n# Build your model input\ninput_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\ninputs = {'input_ids': input_ids}\n\n# Load the Transformers XLNet model as a layer in a Keras model\nxlnet_model = xlnet(inputs)[0]\nxlnet_model = tf.squeeze(xlnet_model[:, -1:, :], axis=1)\ndropout = Dropout(0.1, name='pooled_output')\npooled_output = dropout(xlnet_model, training=False)\n\n# Then build your model output\nRatings = Dense(units=len(data_train.Rating_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='Rating')(pooled_output)\noutputs = {'Rating': Ratings}\n\n# And combine it all in a model object\nmodel4 = Model(inputs=inputs, outputs=outputs, name='XLNet_MultiClass')\n\n# Take a look at the model\nmodel4.summary()","metadata":{"id":"kAuFcEVvh6uo","execution":{"iopub.status.busy":"2022-09-12T11:39:17.983451Z","iopub.execute_input":"2022-09-12T11:39:17.984061Z","iopub.status.idle":"2022-09-12T11:39:22.908939Z","shell.execute_reply.started":"2022-09-12T11:39:17.984023Z","shell.execute_reply":"2022-09-12T11:39:22.907912Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"### ------- Train the model ------- ###\n\n# Set an optimizer\noptimizer = Adam(learning_rate=5e-05,epsilon=1e-08,decay=0.01,clipnorm=1.0)\n\n# Set loss and metrics\nloss = {'Rating': CategoricalCrossentropy(from_logits = True)}\n\n# Compile the model\nmodel4.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy'])\n\n# Ready output data for the model\ny_train = to_categorical(data_train['Rating'])\n\n# Tokenize the input (takes some time)\nx_train = tokenizer(\n          text=data_train['Review'].to_list(),\n          add_special_tokens=True,\n          max_length=max_length,\n          truncation=True,\n          padding=True, \n          return_tensors='tf',\n          return_token_type_ids = False,\n          return_attention_mask = False,\n          verbose = True)\n# Fit the model\nhistory = model4.fit(\n    x={'input_ids': x_train['input_ids']},\n    y={'Rating': y_train},\n    \n    batch_size=64,\n    epochs=10,\n    verbose=1)","metadata":{"id":"zdd4Devah-8W","execution":{"iopub.status.busy":"2022-09-12T11:39:22.910654Z","iopub.execute_input":"2022-09-12T11:39:22.911105Z","iopub.status.idle":"2022-09-12T12:14:09.714339Z","shell.execute_reply.started":"2022-09-12T11:39:22.911051Z","shell.execute_reply":"2022-09-12T12:14:09.713401Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"The model took 31 minutes and 16 seconds to train for 2 epochs.","metadata":{"id":"6MdmNV69ie_-"}},{"cell_type":"markdown","source":"# **Evaluate on Train+Test set(XLNET):**","metadata":{"id":"eqWbCK6sjVz-"}},{"cell_type":"code","source":"model_eval = model4.evaluate(\n    x={'input_ids': x_train['input_ids']},\n    y={'Rating': y_train}\n)","metadata":{"id":"eCL39B4ajcE8","execution":{"iopub.status.busy":"2022-09-12T12:14:09.717637Z","iopub.execute_input":"2022-09-12T12:14:09.717950Z","iopub.status.idle":"2022-09-12T12:15:33.987776Z","shell.execute_reply.started":"2022-09-12T12:14:09.717919Z","shell.execute_reply":"2022-09-12T12:15:33.986776Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"y_train_predicted = model4.predict(\n    x={'input_ids': x_train['input_ids']},\n)","metadata":{"id":"rx6lWBhLje9Y","execution":{"iopub.status.busy":"2022-09-12T12:15:33.989652Z","iopub.execute_input":"2022-09-12T12:15:33.990268Z","iopub.status.idle":"2022-09-12T12:16:46.819539Z","shell.execute_reply.started":"2022-09-12T12:15:33.990230Z","shell.execute_reply":"2022-09-12T12:16:46.818494Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"y_train_predicted['Rating']","metadata":{"id":"aFCzBR9ijpL-","execution":{"iopub.status.busy":"2022-09-12T12:16:46.822853Z","iopub.execute_input":"2022-09-12T12:16:46.823621Z","iopub.status.idle":"2022-09-12T12:16:46.832876Z","shell.execute_reply.started":"2022-09-12T12:16:46.823588Z","shell.execute_reply":"2022-09-12T12:16:46.831817Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"id":"3CnOxfKfjsq2","execution":{"iopub.status.busy":"2022-09-12T12:16:46.834327Z","iopub.execute_input":"2022-09-12T12:16:46.834917Z","iopub.status.idle":"2022-09-12T12:16:46.844457Z","shell.execute_reply.started":"2022-09-12T12:16:46.834862Z","shell.execute_reply":"2022-09-12T12:16:46.843240Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"y_train_pred_max=[np.argmax(i) for i in y_train_predicted['Rating']]","metadata":{"id":"-2U2_4rmjvjm","execution":{"iopub.status.busy":"2022-09-12T12:16:46.845756Z","iopub.execute_input":"2022-09-12T12:16:46.848276Z","iopub.status.idle":"2022-09-12T12:16:46.882087Z","shell.execute_reply.started":"2022-09-12T12:16:46.848169Z","shell.execute_reply":"2022-09-12T12:16:46.881281Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"y_train_actual_max=[np.argmax(i) for i in y_train]","metadata":{"id":"7kIm51U1j0zm","execution":{"iopub.status.busy":"2022-09-12T12:16:46.883544Z","iopub.execute_input":"2022-09-12T12:16:46.884200Z","iopub.status.idle":"2022-09-12T12:16:46.920976Z","shell.execute_reply.started":"2022-09-12T12:16:46.884165Z","shell.execute_reply":"2022-09-12T12:16:46.920066Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nreport = classification_report(y_train_pred_max, y_train_actual_max)\n\nprint(report)","metadata":{"id":"9xSupnBaj5dw","execution":{"iopub.status.busy":"2022-09-12T12:16:46.922026Z","iopub.execute_input":"2022-09-12T12:16:46.922279Z","iopub.status.idle":"2022-09-12T12:16:46.961135Z","shell.execute_reply.started":"2022-09-12T12:16:46.922256Z","shell.execute_reply":"2022-09-12T12:16:46.960146Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train_pred_max, y_train_actual_max), display_labels=np.unique(y_train_actual_max))\ndisp.plot(cmap='Blues') \nplt.grid(False)","metadata":{"id":"kidCU4t0j-Tz","execution":{"iopub.status.busy":"2022-09-12T12:16:46.962431Z","iopub.execute_input":"2022-09-12T12:16:46.962838Z","iopub.status.idle":"2022-09-12T12:16:47.278798Z","shell.execute_reply.started":"2022-09-12T12:16:46.962805Z","shell.execute_reply":"2022-09-12T12:16:47.277826Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"# **Inference(XLNET):**","metadata":{"id":"ZCgmrLAdkKR_"}},{"cell_type":"code","source":"x_test = tokenizer(\n          text=df_test['Review'].to_list(),\n          add_special_tokens=True,\n          max_length=max_length,\n          truncation=True,\n          padding=True, \n          return_tensors='tf',\n          return_token_type_ids = False,\n          return_attention_mask = False,\n          verbose = True)","metadata":{"id":"QOI1m0d7kPYM","execution":{"iopub.status.busy":"2022-09-12T12:16:47.280300Z","iopub.execute_input":"2022-09-12T12:16:47.280620Z","iopub.status.idle":"2022-09-12T12:16:51.763115Z","shell.execute_reply.started":"2022-09-12T12:16:47.280587Z","shell.execute_reply":"2022-09-12T12:16:51.762114Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"label_predicted = model4.predict(\n    x={'input_ids': x_test['input_ids']},\n)","metadata":{"id":"PGqofIdOkREp","execution":{"iopub.status.busy":"2022-09-12T12:16:51.764951Z","iopub.execute_input":"2022-09-12T12:16:51.765394Z","iopub.status.idle":"2022-09-12T12:17:11.598858Z","shell.execute_reply.started":"2022-09-12T12:16:51.765353Z","shell.execute_reply":"2022-09-12T12:17:11.597875Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"label_predicted['Rating']","metadata":{"id":"79cUneqskSvs","execution":{"iopub.status.busy":"2022-09-12T12:17:11.600598Z","iopub.execute_input":"2022-09-12T12:17:11.601310Z","iopub.status.idle":"2022-09-12T12:17:11.609367Z","shell.execute_reply.started":"2022-09-12T12:17:11.601275Z","shell.execute_reply":"2022-09-12T12:17:11.608311Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"label_pred_max=[np.argmax(i) for i in label_predicted['Rating']]","metadata":{"id":"ZNcaRlHOkU1S","execution":{"iopub.status.busy":"2022-09-12T12:17:11.611097Z","iopub.execute_input":"2022-09-12T12:17:11.611455Z","iopub.status.idle":"2022-09-12T12:17:11.625825Z","shell.execute_reply.started":"2022-09-12T12:17:11.611408Z","shell.execute_reply":"2022-09-12T12:17:11.624992Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"label_pred_max[:10]","metadata":{"id":"kKn5cz6FkXQG","execution":{"iopub.status.busy":"2022-09-12T12:17:11.627315Z","iopub.execute_input":"2022-09-12T12:17:11.628043Z","iopub.status.idle":"2022-09-12T12:17:11.635178Z","shell.execute_reply.started":"2022-09-12T12:17:11.628009Z","shell.execute_reply":"2022-09-12T12:17:11.634220Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"We will build the next 2 models the same way as the previous one, notice there are some lines which includes extra functions proper for the model:","metadata":{"id":"kouLSBcZkkq1"}},{"cell_type":"code","source":"#Cheers!!!","metadata":{"id":"AhPdPs8ykms3","execution":{"iopub.status.busy":"2022-09-12T12:17:11.636923Z","iopub.execute_input":"2022-09-12T12:17:11.637628Z","iopub.status.idle":"2022-09-12T12:17:11.643582Z","shell.execute_reply.started":"2022-09-12T12:17:11.637593Z","shell.execute_reply":"2022-09-12T12:17:11.642678Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"# **RoBERTa:**","metadata":{"id":"koQwHFezmI3C"}},{"cell_type":"code","source":"from transformers import RobertaTokenizer, TFRobertaModel, RobertaConfig  ","metadata":{"id":"v0_-ZhMymQa1","execution":{"iopub.status.busy":"2022-09-12T12:17:11.645188Z","iopub.execute_input":"2022-09-12T12:17:11.645553Z","iopub.status.idle":"2022-09-12T12:17:11.680585Z","shell.execute_reply.started":"2022-09-12T12:17:11.645517Z","shell.execute_reply":"2022-09-12T12:17:11.679768Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"### --------- Setup Roberta ---------- ###\n\nmodel_name = 'roberta-base'\n\n# Max length of tokens\nmax_length = 100\n\n# Load transformers config and set output_hidden_states to False\nconfig = RobertaConfig.from_pretrained(model_name)\nconfig.output_hidden_states = False\n\n# Load Roberta tokenizer\ntokenizer = RobertaTokenizer.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n\n# Load the Roberta model\ntransformer_roberta_model = TFRobertaModel.from_pretrained(model_name, config = config)","metadata":{"id":"S3OT0HYFmTaN","execution":{"iopub.status.busy":"2022-09-12T12:17:11.682575Z","iopub.execute_input":"2022-09-12T12:17:11.683218Z","iopub.status.idle":"2022-09-12T12:17:44.979668Z","shell.execute_reply.started":"2022-09-12T12:17:11.683183Z","shell.execute_reply":"2022-09-12T12:17:44.978538Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"### ------- Build the model ------- ###\n\n# Load the MainLayer\nroberta = transformer_roberta_model.layers[0]\n\n# Build your model input\ninput_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\ninputs = {'input_ids': input_ids}\n\n# Load the Transformers RoBERTa model as a layer in a Keras model\nroberta_model = roberta(inputs)[1]\ndropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\npooled_output = dropout(roberta_model, training=False)\n\n# Then build your model output\nRatings = Dense(units=len(data_train.Rating_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='Rating')(pooled_output)\noutputs = {'Rating': Ratings}\n\n# And combine it all in a model object\nmodel2 = Model(inputs=inputs, outputs=outputs, name='RoBERTa_MultiClass')\n\n# Take a look at the model\nmodel2.summary()","metadata":{"id":"xPfL2oCAmWKY","execution":{"iopub.status.busy":"2022-09-12T12:17:44.981072Z","iopub.execute_input":"2022-09-12T12:17:44.982127Z","iopub.status.idle":"2022-09-12T12:17:48.292493Z","shell.execute_reply.started":"2022-09-12T12:17:44.982088Z","shell.execute_reply":"2022-09-12T12:17:48.291332Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"### ------- Train the model ------- ###\n\n# Set an optimizer\noptimizer = Adam(learning_rate=5e-05,epsilon=1e-08,decay=0.01,clipnorm=1.0)\n\n# Set loss and metrics\nloss = {'Rating': CategoricalCrossentropy(from_logits = True)}\n\n# Compile the model\nmodel2.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy'])\n\n# Ready output data for the model\ny_train = to_categorical(data_train['Rating'])\n\n# Tokenize the input (takes some time)\nx_train = tokenizer(\n          text=data_train['Review'].to_list(),\n          add_special_tokens=True,\n          max_length=max_length,\n          truncation=True,\n          padding=True, \n          return_tensors='tf',\n          return_token_type_ids = False,\n          return_attention_mask = True,\n          verbose = True)\n# Fit the model\nhistory = model2.fit(\n    x={'input_ids': x_train['input_ids']},\n    y={'Rating': y_train},\n  \n    batch_size=64,\n    epochs=10,\n    verbose=1)","metadata":{"id":"gw9SvVSgmaZv","execution":{"iopub.status.busy":"2022-09-12T12:17:48.294046Z","iopub.execute_input":"2022-09-12T12:17:48.294644Z","iopub.status.idle":"2022-09-12T12:45:30.581130Z","shell.execute_reply.started":"2022-09-12T12:17:48.294605Z","shell.execute_reply":"2022-09-12T12:45:30.580148Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"The model took 26 minutes to train for 2 epochs.","metadata":{"id":"dTFmPYzSmtRa"}},{"cell_type":"markdown","source":"# **Evaluate on validation set(RoBERTa):**","metadata":{"id":"vdNNw1vRmx_S"}},{"cell_type":"code","source":"model_eval = model2.evaluate(\n    x={'input_ids': x_train['input_ids']},\n    y={'Rating': y_train}\n)","metadata":{"id":"fZIFU5RTnBmc","execution":{"iopub.status.busy":"2022-09-12T12:45:30.582646Z","iopub.execute_input":"2022-09-12T12:45:30.583119Z","iopub.status.idle":"2022-09-12T12:46:37.211711Z","shell.execute_reply.started":"2022-09-12T12:45:30.583082Z","shell.execute_reply":"2022-09-12T12:46:37.210628Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"y_train_predicted = model2.predict(\n    x={'input_ids': x_train['input_ids']},\n)","metadata":{"id":"Ne9_Bq_SnEOV","execution":{"iopub.status.busy":"2022-09-12T12:46:37.213287Z","iopub.execute_input":"2022-09-12T12:46:37.213638Z","iopub.status.idle":"2022-09-12T12:47:40.515114Z","shell.execute_reply.started":"2022-09-12T12:46:37.213602Z","shell.execute_reply":"2022-09-12T12:47:40.514091Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"y_train_predicted['Rating']","metadata":{"id":"mB217pSonE8G","execution":{"iopub.status.busy":"2022-09-12T12:47:40.516738Z","iopub.execute_input":"2022-09-12T12:47:40.517134Z","iopub.status.idle":"2022-09-12T12:47:40.525295Z","shell.execute_reply.started":"2022-09-12T12:47:40.517098Z","shell.execute_reply":"2022-09-12T12:47:40.524261Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"id":"J3Zak1GonGpP","execution":{"iopub.status.busy":"2022-09-12T12:47:40.526880Z","iopub.execute_input":"2022-09-12T12:47:40.527519Z","iopub.status.idle":"2022-09-12T12:47:40.538935Z","shell.execute_reply.started":"2022-09-12T12:47:40.527443Z","shell.execute_reply":"2022-09-12T12:47:40.537955Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"y_train_pred_max=[np.argmax(i) for i in y_train_predicted['Rating']]","metadata":{"id":"gscr2WHonKKZ","execution":{"iopub.status.busy":"2022-09-12T12:47:40.540171Z","iopub.execute_input":"2022-09-12T12:47:40.541080Z","iopub.status.idle":"2022-09-12T12:47:40.578330Z","shell.execute_reply.started":"2022-09-12T12:47:40.541047Z","shell.execute_reply":"2022-09-12T12:47:40.577530Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"y_train_actual_max=[np.argmax(i) for i in y_train]","metadata":{"id":"Hl1uopiynMJo","execution":{"iopub.status.busy":"2022-09-12T12:47:40.579503Z","iopub.execute_input":"2022-09-12T12:47:40.580428Z","iopub.status.idle":"2022-09-12T12:47:40.622649Z","shell.execute_reply.started":"2022-09-12T12:47:40.580395Z","shell.execute_reply":"2022-09-12T12:47:40.621767Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nreport = classification_report(y_train_pred_max, y_train_actual_max)\n\nprint(report)","metadata":{"id":"RYqpHj_dnNvE","execution":{"iopub.status.busy":"2022-09-12T12:47:40.624460Z","iopub.execute_input":"2022-09-12T12:47:40.625119Z","iopub.status.idle":"2022-09-12T12:47:40.663024Z","shell.execute_reply.started":"2022-09-12T12:47:40.625084Z","shell.execute_reply":"2022-09-12T12:47:40.661721Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train_pred_max, y_train_actual_max), display_labels=np.unique(y_train_actual_max))\ndisp.plot(cmap='Blues') \nplt.grid(False)","metadata":{"id":"s0BNnf2NnRGR","execution":{"iopub.status.busy":"2022-09-12T12:47:40.664260Z","iopub.execute_input":"2022-09-12T12:47:40.664589Z","iopub.status.idle":"2022-09-12T12:47:41.524797Z","shell.execute_reply.started":"2022-09-12T12:47:40.664556Z","shell.execute_reply":"2022-09-12T12:47:41.523818Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"# **Inference(RoBERTa):**","metadata":{"id":"5oBHP5ZNnbYm"}},{"cell_type":"code","source":"x_test = tokenizer(\n          text=df_test['Review'].to_list(),\n          add_special_tokens=True,\n          max_length=max_length,\n          truncation=True,\n          padding=True, \n          return_tensors='tf',\n          return_token_type_ids = False,\n          return_attention_mask = False,\n          verbose = True)","metadata":{"id":"CsJwVAu6xJLL","execution":{"iopub.status.busy":"2022-09-12T12:47:41.526135Z","iopub.execute_input":"2022-09-12T12:47:41.526797Z","iopub.status.idle":"2022-09-12T12:47:46.036683Z","shell.execute_reply.started":"2022-09-12T12:47:41.526760Z","shell.execute_reply":"2022-09-12T12:47:46.035741Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"label_predicted = model2.predict(\n    x={'input_ids': x_test['input_ids']},\n)","metadata":{"id":"Zu6d2JSrxNx6","execution":{"iopub.status.busy":"2022-09-12T12:47:46.038311Z","iopub.execute_input":"2022-09-12T12:47:46.038774Z","iopub.status.idle":"2022-09-12T12:48:03.149657Z","shell.execute_reply.started":"2022-09-12T12:47:46.038738Z","shell.execute_reply":"2022-09-12T12:48:03.148639Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"label_predicted['Rating']","metadata":{"id":"4prhNwygxQDP","execution":{"iopub.status.busy":"2022-09-12T12:48:03.151478Z","iopub.execute_input":"2022-09-12T12:48:03.151837Z","iopub.status.idle":"2022-09-12T12:48:03.159518Z","shell.execute_reply.started":"2022-09-12T12:48:03.151802Z","shell.execute_reply":"2022-09-12T12:48:03.158592Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"label_pred_max=[np.argmax(i) for i in label_predicted['Rating']]","metadata":{"id":"j_mxg5F7xT1p","execution":{"iopub.status.busy":"2022-09-12T12:48:03.160972Z","iopub.execute_input":"2022-09-12T12:48:03.161622Z","iopub.status.idle":"2022-09-12T12:48:03.178621Z","shell.execute_reply.started":"2022-09-12T12:48:03.161587Z","shell.execute_reply":"2022-09-12T12:48:03.177700Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"label_pred_max[:10]","metadata":{"id":"CcuNA5H9xUeI","execution":{"iopub.status.busy":"2022-09-12T12:48:03.180171Z","iopub.execute_input":"2022-09-12T12:48:03.180875Z","iopub.status.idle":"2022-09-12T12:48:03.188471Z","shell.execute_reply.started":"2022-09-12T12:48:03.180841Z","shell.execute_reply":"2022-09-12T12:48:03.187471Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"#Cheers!!!","metadata":{"id":"sm6MUu_exXX5","execution":{"iopub.status.busy":"2022-09-12T12:48:03.189928Z","iopub.execute_input":"2022-09-12T12:48:03.191036Z","iopub.status.idle":"2022-09-12T12:48:03.197260Z","shell.execute_reply.started":"2022-09-12T12:48:03.191002Z","shell.execute_reply":"2022-09-12T12:48:03.196235Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"# **DistilBERT:**","metadata":{"id":"bpchyKQtxcwo"}},{"cell_type":"code","source":"from transformers import DistilBertTokenizer, TFDistilBertModel, DistilBertConfig ","metadata":{"id":"bRlvYVufxhTR","execution":{"iopub.status.busy":"2022-09-12T12:48:03.198720Z","iopub.execute_input":"2022-09-12T12:48:03.199867Z","iopub.status.idle":"2022-09-12T12:48:03.214699Z","shell.execute_reply.started":"2022-09-12T12:48:03.199833Z","shell.execute_reply":"2022-09-12T12:48:03.213788Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"### --------- Setup DistilBERT ---------- ###\n\nmodel_name = 'distilbert-base-uncased'\n\n# Max length of tokens\nmax_length = 100\n\n# Load transformers config and set output_hidden_states to False\nconfig = DistilBertConfig.from_pretrained(model_name)\nconfig.output_hidden_states = False\n\n# Load Distilbert tokenizer\ntokenizer = DistilBertTokenizer.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n\n# Load the Distilbert model\ntransformer_distilbert_model = TFDistilBertModel.from_pretrained(model_name, config = config)","metadata":{"id":"QsRkzF0Qxjfh","execution":{"iopub.status.busy":"2022-09-12T12:48:03.216515Z","iopub.execute_input":"2022-09-12T12:48:03.217435Z","iopub.status.idle":"2022-09-12T12:48:23.075580Z","shell.execute_reply.started":"2022-09-12T12:48:03.217380Z","shell.execute_reply":"2022-09-12T12:48:23.074519Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"### ------- Build the model ------- ###\n\n# Load the MainLayer\ndistilbert = transformer_distilbert_model.layers[0]\n\n# Build your model input\ninput_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\ninputs = {'input_ids': input_ids}\n\n# Load the Transformers DistilBERT model as a layer in a Keras model\ndistilbert_model = distilbert(inputs)[0][:,0,:]\ndropout = Dropout(0.1, name='pooled_output')\npooled_output = dropout(distilbert_model, training=False)\n\n# Then build your model output\nRatings = Dense(units=len(data_train.Rating_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='Rating')(pooled_output)\noutputs = {'Rating': Ratings}\n\n# And combine it all in a model object\nmodel3 = Model(inputs=inputs, outputs=outputs, name='DistilBERT_MultiClass')\n\n# Take a look at the model\nmodel3.summary()","metadata":{"id":"Ggoy5xBDxlh4","execution":{"iopub.status.busy":"2022-09-12T12:48:23.077216Z","iopub.execute_input":"2022-09-12T12:48:23.077549Z","iopub.status.idle":"2022-09-12T12:48:24.679017Z","shell.execute_reply.started":"2022-09-12T12:48:23.077513Z","shell.execute_reply":"2022-09-12T12:48:24.678039Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"### ------- Train the model ------- ###\n\n# Set an optimizer\noptimizer = Adam(learning_rate=5e-05,epsilon=1e-08,decay=0.01,clipnorm=1.0)\n\n# Set loss and metrics\nloss = {'Rating': CategoricalCrossentropy(from_logits = True)}\n\n# Compile the model\nmodel3.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy'])\n\n# Ready output data for the model\ny_train = to_categorical(data_train['Rating'])\n\n# Tokenize the input (takes some time)\nx_train = tokenizer(\n          text=data_train['Review'].to_list(),\n          add_special_tokens=True,\n          max_length=max_length,\n          truncation=True,\n          padding=True, \n          return_tensors='tf',\n          return_token_type_ids = False,\n          return_attention_mask = True,\n          verbose = True)\n# Fit the model\nhistory = model3.fit(\n    x={'input_ids': x_train['input_ids']},\n    y={'Rating': y_train},\n    \n    batch_size=64,\n    epochs=10,\n    verbose=1)","metadata":{"id":"55_YfnXrxpuU","execution":{"iopub.status.busy":"2022-09-12T12:48:24.680578Z","iopub.execute_input":"2022-09-12T12:48:24.680969Z","iopub.status.idle":"2022-09-12T13:03:49.001952Z","shell.execute_reply.started":"2022-09-12T12:48:24.680931Z","shell.execute_reply":"2022-09-12T13:03:49.000874Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"The model took 14 minutes to train for 2 epochs.","metadata":{"id":"48Rh_0Jxx1mu"}},{"cell_type":"markdown","source":"# **Evaluate on Train+Test set(DistilBERT):**","metadata":{"id":"0YgxcDDZx67P"}},{"cell_type":"code","source":"model_eval = model3.evaluate(\n    x={'input_ids': x_train['input_ids']},\n    y={'Rating': y_train}\n)","metadata":{"id":"3wks0zncyQqF","execution":{"iopub.status.busy":"2022-09-12T13:03:49.012469Z","iopub.execute_input":"2022-09-12T13:03:49.012778Z","iopub.status.idle":"2022-09-12T13:04:22.657476Z","shell.execute_reply.started":"2022-09-12T13:03:49.012750Z","shell.execute_reply":"2022-09-12T13:04:22.656552Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"y_train_predicted = model3.predict(\n    x={'input_ids': x_train['input_ids']},\n)","metadata":{"id":"6tMp7hgFyTIl","execution":{"iopub.status.busy":"2022-09-12T13:04:22.660172Z","iopub.execute_input":"2022-09-12T13:04:22.660480Z","iopub.status.idle":"2022-09-12T13:04:54.146243Z","shell.execute_reply.started":"2022-09-12T13:04:22.660451Z","shell.execute_reply":"2022-09-12T13:04:54.145238Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"y_train_predicted['Rating']","metadata":{"id":"N3mJXKlnyUtX","execution":{"iopub.status.busy":"2022-09-12T13:04:54.148004Z","iopub.execute_input":"2022-09-12T13:04:54.148704Z","iopub.status.idle":"2022-09-12T13:04:54.158324Z","shell.execute_reply.started":"2022-09-12T13:04:54.148667Z","shell.execute_reply":"2022-09-12T13:04:54.157387Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"id":"_3Jl4N5VyWVD","execution":{"iopub.status.busy":"2022-09-12T13:04:54.160607Z","iopub.execute_input":"2022-09-12T13:04:54.161789Z","iopub.status.idle":"2022-09-12T13:04:54.168930Z","shell.execute_reply.started":"2022-09-12T13:04:54.161754Z","shell.execute_reply":"2022-09-12T13:04:54.167776Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"y_train_pred_max=[np.argmax(i) for i in y_train_predicted['Rating']]","metadata":{"id":"ujrdGfZzyX-g","execution":{"iopub.status.busy":"2022-09-12T13:04:54.170293Z","iopub.execute_input":"2022-09-12T13:04:54.171162Z","iopub.status.idle":"2022-09-12T13:04:54.204615Z","shell.execute_reply.started":"2022-09-12T13:04:54.171126Z","shell.execute_reply":"2022-09-12T13:04:54.203798Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"y_train_actual_max=[np.argmax(i) for i in y_train]","metadata":{"id":"9gHvIweAyZl5","execution":{"iopub.status.busy":"2022-09-12T13:04:54.205778Z","iopub.execute_input":"2022-09-12T13:04:54.206648Z","iopub.status.idle":"2022-09-12T13:04:54.242781Z","shell.execute_reply.started":"2022-09-12T13:04:54.206610Z","shell.execute_reply":"2022-09-12T13:04:54.241946Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nreport = classification_report(y_train_pred_max, y_train_actual_max)\n\nprint(report)","metadata":{"id":"blylOwqaybBA","execution":{"iopub.status.busy":"2022-09-12T13:04:54.243996Z","iopub.execute_input":"2022-09-12T13:04:54.244845Z","iopub.status.idle":"2022-09-12T13:04:54.282869Z","shell.execute_reply.started":"2022-09-12T13:04:54.244810Z","shell.execute_reply":"2022-09-12T13:04:54.282012Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train_pred_max, y_train_actual_max), display_labels=np.unique(y_train_actual_max))\ndisp.plot(cmap='Blues') \nplt.grid(False)","metadata":{"id":"jY-Qm9Qdycne","execution":{"iopub.status.busy":"2022-09-12T13:04:54.284001Z","iopub.execute_input":"2022-09-12T13:04:54.286124Z","iopub.status.idle":"2022-09-12T13:04:54.631712Z","shell.execute_reply.started":"2022-09-12T13:04:54.286090Z","shell.execute_reply":"2022-09-12T13:04:54.630822Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"# **Inference(DistilBERT):**","metadata":{"id":"21nSujTvyffI"}},{"cell_type":"code","source":"x_test = tokenizer(\n          text=df_test['Review'].to_list(),\n          add_special_tokens=True,\n          max_length=max_length,\n          truncation=True,\n          padding=True, \n          return_tensors='tf',\n          return_token_type_ids = False,\n          return_attention_mask = False,\n          verbose = True)","metadata":{"id":"LDEQ4QCKyqVh","execution":{"iopub.status.busy":"2022-09-12T13:04:54.633231Z","iopub.execute_input":"2022-09-12T13:04:54.633587Z","iopub.status.idle":"2022-09-12T13:05:08.913272Z","shell.execute_reply.started":"2022-09-12T13:04:54.633552Z","shell.execute_reply":"2022-09-12T13:05:08.912098Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"label_predicted = model3.predict(\n    x={'input_ids': x_test['input_ids']},\n)","metadata":{"id":"lh3csmrFysQh","execution":{"iopub.status.busy":"2022-09-12T13:05:08.914829Z","iopub.execute_input":"2022-09-12T13:05:08.915321Z","iopub.status.idle":"2022-09-12T13:05:17.491022Z","shell.execute_reply.started":"2022-09-12T13:05:08.915283Z","shell.execute_reply":"2022-09-12T13:05:17.489967Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"label_predicted['Rating']","metadata":{"id":"h_bs8BUAyt2y","execution":{"iopub.status.busy":"2022-09-12T13:05:17.494329Z","iopub.execute_input":"2022-09-12T13:05:17.494634Z","iopub.status.idle":"2022-09-12T13:05:17.502840Z","shell.execute_reply.started":"2022-09-12T13:05:17.494607Z","shell.execute_reply":"2022-09-12T13:05:17.501726Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"label_pred_max=[np.argmax(i) for i in label_predicted['Rating']]","metadata":{"id":"05WlkcFYyvmd","execution":{"iopub.status.busy":"2022-09-12T13:05:17.504536Z","iopub.execute_input":"2022-09-12T13:05:17.505371Z","iopub.status.idle":"2022-09-12T13:05:17.528727Z","shell.execute_reply.started":"2022-09-12T13:05:17.505334Z","shell.execute_reply":"2022-09-12T13:05:17.527757Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"label_pred_max[:10]","metadata":{"id":"VFkyqi68yxH2","execution":{"iopub.status.busy":"2022-09-12T13:05:17.530044Z","iopub.execute_input":"2022-09-12T13:05:17.530668Z","iopub.status.idle":"2022-09-12T13:05:17.537369Z","shell.execute_reply.started":"2022-09-12T13:05:17.530634Z","shell.execute_reply":"2022-09-12T13:05:17.536452Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"#Cheers!!!","metadata":{"id":"U9ZS4tl1yznV","execution":{"iopub.status.busy":"2022-09-12T13:05:17.538776Z","iopub.execute_input":"2022-09-12T13:05:17.539501Z","iopub.status.idle":"2022-09-12T13:05:17.546421Z","shell.execute_reply.started":"2022-09-12T13:05:17.539465Z","shell.execute_reply":"2022-09-12T13:05:17.545307Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"# **Discussion:**","metadata":{"id":"0xnAijlDy68p"}},{"cell_type":"markdown","source":"In general the performance of the four models was similar, supporting the idea that BERT is the middle term of trade-off between accuracy and training time, whereas DistilBERT was the fastest by far, but having a lower accuracy than the previous as is explained by HuggingFace it achieves 95% accuracy of BERT, finally RoBERTa and XLNet were the models with highest accuracy and at the same time the slowest.\n\nI have submitted the predition of the testing set for all models and the best one was RoBERTa reaching 68.62% of accuracy and the lowest was DistilBERT reaching 67.90%. We can say there is a slight difference but in terms of number of misclassifications the gap is huge, however the big challenge of the current task is how to deal with an unbalanced dataset, this is the main and perhaps the unique reason why we have such a poor performance even in the best one, despite the fact that increasing the max_length of sequences can increase a little bit the accuracy too, but not significatively. The method I would apply to solve this problem is undersampling in which we reduce the number of instances to the less frequent class which corresponds to 7.072 (Negative) as such number of instances is not too small and having 5 classes the dataset should finally have 35.360 sentences to compute, but obviously we are getting rid randomly of a big portion of the data.\n\nAnother possible solution could be to get rid of those reviews which are \"vague\" such as those with only one or two words classified as neutral, those really does not add too much to the training, but in contrast are others which have just a couple of words and are useful. This process would take a long time to do because it have to be done one by one, but it surely solves the problem.\n\nAlso I have to inform that I have trained for more than 2 epochs each model but the accuracy didn't increase or even decreased after the 3rd or 4th epoch, this is why in order to avoid more complex functions or early stopping I set to 2 epochs.\n\nI would like to know any feedback in order to increase the performance of the models or tell me if you found a different one even better!\n\nIf you liked this notebook I would appreciate so much your upvote if you want to see more projects/tutorials like this one. I encourage you to see my projects portfolio, am sure you will love it.\n\nThank you!","metadata":{"id":"BUTHRQgHy_88"}}]}